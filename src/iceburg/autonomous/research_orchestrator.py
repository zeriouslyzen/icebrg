"""
Autonomous Research Orchestrator for ICEBURG

Integrates existing components into an autonomous research loop that can:
- Generate curiosity-driven queries
- Execute research without human input
- Detect emergence and breakthroughs
- Generate self-improvements
- Coordinate research cycles
"""

import asyncio
import json
import logging
import time
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, field
from pathlib import Path
import uuid
from collections import deque

logger = logging.getLogger(__name__)


@dataclass
class ResearchQuery:
    """A research query generated by the curiosity engine."""
    query_id: str
    query_text: str
    complexity: float
    domain: str
    priority: int
    generated_at: float
    metadata: Dict[str, Any] = field(default_factory=dict)


@dataclass
class ResearchResult:
    """Result from executing a research query."""
    query_id: str
    result_text: str
    success: bool
    execution_time: float
    quality_score: float
    emergence_detected: bool = False
    breakthrough_potential: float = 0.0
    metadata: Dict[str, Any] = field(default_factory=dict)


@dataclass
class EmergencePattern:
    """Pattern detected by the emergence engine."""
    pattern_id: str
    pattern_type: str
    description: str
    confidence: float
    affected_queries: List[str] = field(default_factory=list)
    breakthrough_potential: float = 0.0
    metadata: Dict[str, Any] = field(default_factory=list)


@dataclass
class ImprovementProposal:
    """Proposal for system improvement."""
    proposal_id: str
    title: str
    description: str
    improvement_type: str
    expected_benefit: float
    implementation_effort: float
    risk_level: str
    generated_at: float
    metadata: Dict[str, Any] = field(default_factory=dict)


class AutonomousResearchOrchestrator:
    """
    Orchestrates autonomous research cycles for ICEBURG.
    
    Coordinates between:
    - Curiosity Engine (query generation)
    - Emergence Engine (pattern detection)
    - Protocol execution (research execution)
    - Specification Generator (improvement proposals)
    - Dynamic Agent Factory (agent creation)
    """
    
    def __init__(self, config: Dict[str, Any] = None):
        """Initialize autonomous research orchestrator."""
        self.config = config or {}
        self.active = False
        self.cycle_count = 0
        self.results_history = deque(maxlen=1000)
        self.improvement_queue = deque(maxlen=100)
        
        # Component references (will be injected)
        self.curiosity_engine = None
        self.emergence_engine = None
        self.protocol = None
        self.specification_generator = None
        self.agent_factory = None
        self.approval_queue = None
        
        # Research state
        self.current_queries = {}
        self.active_agents = {}
        self.emergence_patterns = []
        
        # Configuration
        self.max_concurrent_queries = self.config.get("max_concurrent_queries", 5)
        self.research_cycle_interval = self.config.get("research_cycle_interval", 300)  # 5 minutes
        self.emergence_threshold = self.config.get("emergence_threshold", 0.7)
        self.breakthrough_threshold = self.config.get("breakthrough_threshold", 0.8)
        
        # Research domains
        self.research_domains = [
            "artificial_intelligence",
            "machine_learning",
            "neuroscience",
            "physics",
            "mathematics",
            "computer_science",
            "psychology",
            "philosophy"
        ]
    
    async def start_autonomous_research(self):
        """Start the autonomous research loop."""
        if self.active:
            logger.warning("Autonomous research already active")
            return
        
        logger.info("Starting autonomous research orchestrator")
        self.active = True
        
        # Initialize components
        await self._initialize_components()
        
        # Start research cycle loop
        asyncio.create_task(self._research_cycle_loop())
        
        logger.info("Autonomous research started")
    
    async def stop_autonomous_research(self):
        """Stop the autonomous research loop."""
        if not self.active:
            return
        
        logger.info("Stopping autonomous research orchestrator")
        self.active = False
        
        # Cancel any running queries
        for query_id in list(self.current_queries.keys()):
            await self._cancel_query(query_id)
        
        logger.info("Autonomous research stopped")
    
    async def autonomous_research_cycle(self):
        """Execute a single autonomous research cycle."""
        logger.info(f"Starting research cycle {self.cycle_count + 1}")
        
        try:
            # 1. Generate curiosity queries
            queries = await self._generate_curiosity_queries()
            logger.info(f"Generated {len(queries)} curiosity queries")
            
            # 2. Execute research queries
            results = await self._execute_research_queries(queries)
            logger.info(f"Executed {len(results)} research queries")
            
            # 3. Detect emergence patterns
            patterns = await self._detect_emergence_patterns(results)
            logger.info(f"Detected {len(patterns)} emergence patterns")
            
            # 4. Generate improvement proposals
            improvements = await self._generate_improvement_proposals(results, patterns)
            logger.info(f"Generated {len(improvements)} improvement proposals")
            
            # 5. Queue improvements for approval
            await self._queue_improvements(improvements)
            
            # 6. Update research state
            await self._update_research_state(results, patterns, improvements)
            
            self.cycle_count += 1
            logger.info(f"Research cycle {self.cycle_count} completed")
            
        except Exception as e:
            logger.error(f"Research cycle failed: {e}")
    
    async def _initialize_components(self):
        """Initialize all required components."""
        try:
            # Import and initialize components
            from ..curiosity.curiosity_engine import CuriosityEngine
            from ..emergence_engine import EmergenceEngine
            from ..protocol import iceberg_protocol
            from ..evolution.specification_generator import SpecificationGenerator
            from ..agents.dynamic_agent_factory import DynamicAgentFactory
            from ..learning.autonomous_improvement import ApprovalQueue
            
            self.curiosity_engine = CuriosityEngine()
            self.emergence_engine = EmergenceEngine({})  # Pass empty config dict
            self.protocol = iceberg_protocol
            self.specification_generator = SpecificationGenerator()
            self.agent_factory = DynamicAgentFactory()
            self.approval_queue = ApprovalQueue()
            
            logger.info("All components initialized successfully")
            
        except Exception as e:
            logger.error(f"Failed to initialize components: {e}")
            raise
    
    async def _generate_curiosity_queries(self) -> List[ResearchQuery]:
        """Generate curiosity-driven research queries."""
        queries = []
        
        try:
            if self.curiosity_engine:
                # Generate queries using curiosity engine
                curiosity_queries = await self.curiosity_engine.generate_curiosity_queries(
                    domains=self.research_domains,
                    count=self.max_concurrent_queries
                )
                
                for query_text in curiosity_queries:
                    query = ResearchQuery(
                        query_id=str(uuid.uuid4()),
                        query_text=query_text,
                        complexity=self._estimate_query_complexity(query_text),
                        domain=self._classify_query_domain(query_text),
                        priority=self._calculate_query_priority(query_text),
                        generated_at=time.time(),
                        metadata={"source": "curiosity_engine"}
                    )
                    queries.append(query)
            else:
                # Fallback to predefined queries
                queries = await self._generate_fallback_queries()
            
            return queries
            
        except Exception as e:
            logger.error(f"Failed to generate curiosity queries: {e}")
            return []
    
    async def _execute_research_queries(self, queries: List[ResearchQuery]) -> List[ResearchResult]:
        """Execute research queries using ICEBURG protocol."""
        results = []
        
        # Execute queries in parallel (limited by max_concurrent_queries)
        semaphore = asyncio.Semaphore(self.max_concurrent_queries)
        
        async def execute_single_query(query: ResearchQuery) -> ResearchResult:
            async with semaphore:
                return await self._execute_single_query(query)
        
        # Execute all queries
        tasks = [execute_single_query(query) for query in queries]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Filter out exceptions and convert to ResearchResult
        valid_results = []
        for result in results:
            if isinstance(result, ResearchResult):
                valid_results.append(result)
            elif isinstance(result, Exception):
                logger.error(f"Query execution failed: {result}")
        
        return valid_results
    
    async def _execute_single_query(self, query: ResearchQuery) -> ResearchResult:
        """Execute a single research query."""
        start_time = time.time()
        
        try:
            # Add query to current queries
            self.current_queries[query.query_id] = query
            
            # Execute using ICEBURG protocol
            if self.protocol:
                result_text = self.protocol(
                    query.query_text,
                    fast=False,  # Use full mode for research
                    verbose=False
                )
            else:
                # Fallback simulation
                result_text = await self._simulate_research_execution(query)
            
            execution_time = time.time() - start_time
            
            # Calculate quality score
            quality_score = self._calculate_quality_score(query, result_text)
            
            # Check for emergence
            emergence_detected = await self._check_emergence(query, result_text)
            breakthrough_potential = self._calculate_breakthrough_potential(result_text)
            
            result = ResearchResult(
                query_id=query.query_id,
                result_text=result_text,
                success=True,
                execution_time=execution_time,
                quality_score=quality_score,
                emergence_detected=emergence_detected,
                breakthrough_potential=breakthrough_potential,
                metadata={
                    "query_complexity": query.complexity,
                    "domain": query.domain,
                    "priority": query.priority
                }
            )
            
            # Remove from current queries
            self.current_queries.pop(query.query_id, None)
            
            return result
            
        except Exception as e:
            logger.error(f"Query execution failed for {query.query_id}: {e}")
            
            # Remove from current queries
            self.current_queries.pop(query.query_id, None)
            
            return ResearchResult(
                query_id=query.query_id,
                result_text="",
                success=False,
                execution_time=time.time() - start_time,
                quality_score=0.0,
                metadata={"error": str(e)}
            )
    
    async def _detect_emergence_patterns(self, results: List[ResearchResult]) -> List[EmergencePattern]:
        """Detect emergence patterns in research results."""
        patterns = []
        
        try:
            if self.emergence_engine:
                # Use emergence engine to detect patterns
                # Use emergence engine to analyze results
                emergence_analysis = self.emergence_engine.analyze(limit=100)
                detected_patterns = [emergence_analysis] if emergence_analysis.get("emergence_detected") else []
                
                for pattern_data in detected_patterns:
                    pattern = EmergencePattern(
                        pattern_id=str(uuid.uuid4()),
                        pattern_type=pattern_data.get("type", "unknown"),
                        description=pattern_data.get("description", ""),
                        confidence=pattern_data.get("confidence", 0.0),
                        affected_queries=[r.query_id for r in results if r.success],
                        breakthrough_potential=pattern_data.get("breakthrough_potential", 0.0),
                        metadata=pattern_data.get("metadata", {})
                    )
                    patterns.append(pattern)
            else:
                # Fallback pattern detection
                patterns = await self._detect_fallback_patterns(results)
            
            return patterns
            
        except Exception as e:
            logger.error(f"Failed to detect emergence patterns: {e}")
            return []
    
    async def _generate_improvement_proposals(self, results: List[ResearchResult], 
                                            patterns: List[EmergencePattern]) -> List[ImprovementProposal]:
        """Generate improvement proposals based on research results and patterns."""
        proposals = []
        
        try:
            # Analyze performance and generate proposals
            if self.specification_generator:
                # Get performance analysis
                analysis = await self.specification_generator.analyze_system_performance()
                
                # Identify opportunities
                opportunities = self.specification_generator.identify_optimization_opportunities(analysis)
                
                # Generate proposals for each opportunity
                for opportunity in opportunities[:3]:  # Limit to top 3 opportunities
                    proposal = ImprovementProposal(
                        proposal_id=str(uuid.uuid4()),
                        title=f"Improve {opportunity.name}",
                        description=opportunity.description,
                        improvement_type=opportunity.optimization_type,
                        expected_benefit=opportunity.expected_improvement,
                        implementation_effort=opportunity.effort_score,
                        risk_level=opportunity.risk_level,
                        generated_at=time.time(),
                        metadata={
                            "opportunity_name": opportunity.name,
                            "impact_score": opportunity.impact_score,
                            "affected_components": opportunity.affected_components
                        }
                    )
                    proposals.append(proposal)
            
            # Generate proposals based on emergence patterns
            for pattern in patterns:
                if pattern.breakthrough_potential > self.breakthrough_threshold:
                    proposal = ImprovementProposal(
                        proposal_id=str(uuid.uuid4()),
                        title=f"Explore {pattern.pattern_type} breakthrough",
                        description=f"Investigate breakthrough potential in {pattern.description}",
                        improvement_type="research_expansion",
                        expected_benefit=pattern.breakthrough_potential,
                        implementation_effort=0.7,
                        risk_level="medium",
                        generated_at=time.time(),
                        metadata={
                            "pattern_id": pattern.pattern_id,
                            "pattern_type": pattern.pattern_type,
                            "breakthrough_potential": pattern.breakthrough_potential
                        }
                    )
                    proposals.append(proposal)
            
            return proposals
            
        except Exception as e:
            logger.error(f"Failed to generate improvement proposals: {e}")
            return []
    
    async def _queue_improvements(self, improvements: List[ImprovementProposal]):
        """Queue improvements for approval."""
        try:
            if self.approval_queue:
                for improvement in improvements:
                    await self.approval_queue.add_improvement(improvement)
                    self.improvement_queue.append(improvement)
                
                logger.info(f"Queued {len(improvements)} improvements for approval")
            else:
                logger.warning("No approval queue available - improvements not queued")
                
        except Exception as e:
            logger.error(f"Failed to queue improvements: {e}")
    
    async def _update_research_state(self, results: List[ResearchResult], 
                                   patterns: List[EmergencePattern], 
                                   improvements: List[ImprovementProposal]):
        """Update internal research state."""
        # Add results to history
        for result in results:
            self.results_history.append(result)
        
        # Update emergence patterns
        self.emergence_patterns.extend(patterns)
        
        # Keep only recent patterns (last 100)
        if len(self.emergence_patterns) > 100:
            self.emergence_patterns = self.emergence_patterns[-100:]
        
        # Update active agents if needed
        await self._update_active_agents(results, patterns)
    
    async def _update_active_agents(self, results: List[ResearchResult], 
                                  patterns: List[EmergencePattern]):
        """Update active agents based on research results."""
        try:
            if not self.agent_factory:
                return
            
            # Create specialized agents for high-quality results
            for result in results:
                if result.quality_score > 0.8 and result.emergence_detected:
                    agent_name = f"specialist_{result.query_id[:8]}"
                    await self.agent_factory.create_specialized_agent(
                        name=agent_name,
                        specialization=result.metadata.get("domain", "general"),
                        capabilities=["deep_analysis", "pattern_recognition"]
                    )
                    self.active_agents[agent_name] = {
                        "created_at": time.time(),
                        "specialization": result.metadata.get("domain", "general"),
                        "quality_threshold": 0.8
                    }
            
            # Create pattern analysis agents
            for pattern in patterns:
                if pattern.confidence > self.emergence_threshold:
                    agent_name = f"pattern_analyzer_{pattern.pattern_id[:8]}"
                    await self.agent_factory.create_specialized_agent(
                        name=agent_name,
                        specialization="pattern_analysis",
                        capabilities=["emergence_detection", "breakthrough_analysis"]
                    )
                    self.active_agents[agent_name] = {
                        "created_at": time.time(),
                        "specialization": "pattern_analysis",
                        "pattern_id": pattern.pattern_id
                    }
            
        except Exception as e:
            logger.error(f"Failed to update active agents: {e}")
    
    async def _research_cycle_loop(self):
        """Main research cycle loop."""
        while self.active:
            try:
                await self.autonomous_research_cycle()
                await asyncio.sleep(self.research_cycle_interval)
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"Research cycle loop error: {e}")
                await asyncio.sleep(60)  # Wait before retrying
    
    # Helper methods
    def _estimate_query_complexity(self, query_text: str) -> float:
        """Estimate query complexity (0-1)."""
        complexity = 0.5  # Base complexity
        
        # Length factor
        if len(query_text) > 100:
            complexity += 0.2
        if len(query_text) > 200:
            complexity += 0.1
        
        # Complexity keywords
        complex_keywords = ["analyze", "compare", "evaluate", "design", "create", "develop"]
        for keyword in complex_keywords:
            if keyword in query_text.lower():
                complexity += 0.1
        
        return min(1.0, complexity)
    
    def _classify_query_domain(self, query_text: str) -> str:
        """Classify query domain."""
        domain_keywords = {
            "artificial_intelligence": ["ai", "artificial intelligence", "machine learning", "neural network"],
            "physics": ["physics", "quantum", "relativity", "energy", "force"],
            "mathematics": ["math", "mathematics", "equation", "theorem", "proof"],
            "neuroscience": ["brain", "neural", "cognitive", "consciousness", "mind"],
            "computer_science": ["algorithm", "programming", "software", "computer", "data structure"]
        }
        
        query_lower = query_text.lower()
        for domain, keywords in domain_keywords.items():
            if any(keyword in query_lower for keyword in keywords):
                return domain
        
        return "general"
    
    def _calculate_query_priority(self, query_text: str) -> int:
        """Calculate query priority (1-10, higher is more important)."""
        priority = 5  # Base priority
        
        # High priority keywords
        high_priority = ["breakthrough", "discovery", "new", "novel", "revolutionary"]
        for keyword in high_priority:
            if keyword in query_text.lower():
                priority += 2
        
        # Medium priority keywords
        medium_priority = ["improve", "optimize", "enhance", "better", "faster"]
        for keyword in medium_priority:
            if keyword in query_text.lower():
                priority += 1
        
        return min(10, max(1, priority))
    
    def _calculate_quality_score(self, query: ResearchQuery, result_text: str) -> float:
        """Calculate quality score for research result (0-1)."""
        if not result_text:
            return 0.0
        
        score = 0.5  # Base score
        
        # Length factor
        if len(result_text) > 500:
            score += 0.1
        if len(result_text) > 1000:
            score += 0.1
        
        # Quality indicators
        quality_indicators = ["evidence", "research", "analysis", "conclusion", "summary"]
        for indicator in quality_indicators:
            if indicator in result_text.lower():
                score += 0.05
        
        # Complexity matching
        if query.complexity > 0.7 and len(result_text) > 800:
            score += 0.1
        
        return min(1.0, score)
    
    async def _check_emergence(self, query: ResearchQuery, result_text: str) -> bool:
        """Check if result shows signs of emergence."""
        emergence_indicators = [
            "novel", "unexpected", "surprising", "breakthrough",
            "new pattern", "emergent", "unprecedented"
        ]
        
        result_lower = result_text.lower()
        return any(indicator in result_lower for indicator in emergence_indicators)
    
    def _calculate_breakthrough_potential(self, result_text: str) -> float:
        """Calculate breakthrough potential (0-1)."""
        if not result_text:
            return 0.0
        
        potential = 0.0
        
        # Breakthrough keywords
        breakthrough_keywords = ["breakthrough", "revolutionary", "paradigm", "fundamental"]
        for keyword in breakthrough_keywords:
            if keyword in result_text.lower():
                potential += 0.2
        
        # Novelty indicators
        novelty_indicators = ["new", "novel", "unprecedented", "first", "discovery"]
        for indicator in novelty_indicators:
            if indicator in result_text.lower():
                potential += 0.1
        
        return min(1.0, potential)
    
    async def _generate_fallback_queries(self) -> List[ResearchQuery]:
        """Generate fallback queries when curiosity engine is unavailable."""
        fallback_queries = [
            "What are the latest advances in artificial intelligence?",
            "How can machine learning be improved?",
            "What are the challenges in AGI development?",
            "How does consciousness relate to intelligence?",
            "What are the ethical implications of advanced AI?"
        ]
        
        queries = []
        for query_text in fallback_queries:
            query = ResearchQuery(
                query_id=str(uuid.uuid4()),
                query_text=query_text,
                complexity=self._estimate_query_complexity(query_text),
                domain=self._classify_query_domain(query_text),
                priority=self._calculate_query_priority(query_text),
                generated_at=time.time(),
                metadata={"source": "fallback"}
            )
            queries.append(query)
        
        return queries
    
    async def _simulate_research_execution(self, query: ResearchQuery) -> str:
        """Simulate research execution for testing."""
        await asyncio.sleep(1)  # Simulate processing time
        
        return f"Research result for: {query.query_text}\n\nThis is a simulated research result that would normally be generated by ICEBURG's full protocol execution. The query was classified as {query.domain} domain with complexity {query.complexity:.2f} and priority {query.priority}."
    
    async def _detect_fallback_patterns(self, results: List[ResearchResult]) -> List[EmergencePattern]:
        """Detect patterns using fallback method."""
        patterns = []
        
        # Simple pattern detection based on common themes
        themes = {}
        for result in results:
            if result.success:
                # Extract potential themes from result text
                words = result.result_text.lower().split()
                for word in words:
                    if len(word) > 5:  # Only consider longer words
                        themes[word] = themes.get(word, 0) + 1
        
        # Create patterns for frequent themes
        for theme, count in themes.items():
            if count > 1:  # Theme appears in multiple results
                pattern = EmergencePattern(
                    pattern_id=str(uuid.uuid4()),
                    pattern_type="theme",
                    description=f"Common theme: {theme}",
                    confidence=min(1.0, count / len(results)),
                    affected_queries=[r.query_id for r in results if theme in r.result_text.lower()],
                    breakthrough_potential=0.3,
                    metadata={"theme": theme, "frequency": count}
                )
                patterns.append(pattern)
        
        return patterns
    
    async def _cancel_query(self, query_id: str):
        """Cancel a running query."""
        if query_id in self.current_queries:
            del self.current_queries[query_id]
            logger.info(f"Cancelled query {query_id}")
    
    def get_research_status(self) -> Dict[str, Any]:
        """Get current research status."""
        return {
            "active": self.active,
            "cycle_count": self.cycle_count,
            "current_queries": len(self.current_queries),
            "results_history": len(self.results_history),
            "emergence_patterns": len(self.emergence_patterns),
            "improvement_queue": len(self.improvement_queue),
            "active_agents": len(self.active_agents)
        }


# Example usage and testing
if __name__ == "__main__":
    import asyncio
    
    async def test_autonomous_research():
        # Create orchestrator
        orchestrator = AutonomousResearchOrchestrator({
            "max_concurrent_queries": 3,
            "research_cycle_interval": 10,  # 10 seconds for testing
            "emergence_threshold": 0.6,
            "breakthrough_threshold": 0.7
        })
        
        # Start autonomous research
        await orchestrator.start_autonomous_research()
        
        # Let it run for a bit
        await asyncio.sleep(30)
        
        # Check status
        status = orchestrator.get_research_status()
        print("Research Status:")
        print(f"  Active: {status['active']}")
        print(f"  Cycle Count: {status['cycle_count']}")
        print(f"  Current Queries: {status['current_queries']}")
        print(f"  Results History: {status['results_history']}")
        print(f"  Emergence Patterns: {status['emergence_patterns']}")
        print(f"  Improvement Queue: {status['improvement_queue']}")
        print(f"  Active Agents: {status['active_agents']}")
        
        # Stop research
        await orchestrator.stop_autonomous_research()
        print("Autonomous research stopped")
    
    # Run test
    asyncio.run(test_autonomous_research())
